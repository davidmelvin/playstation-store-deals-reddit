package main

import (
	"context"
	"encoding/json"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"strings"
	"time"

	"github.com/gocolly/colly"
	"github.com/jzelinskie/geddit"
	"github.com/mitchellh/mapstructure"
)

const productURLPrefix = "https://store.playstation.com/en-us/product/"
const testingURL = "https://store.playstation.com/en-us/category/99369cc3-0ac2-46de-b437-e8c70c79f55e"
const ProductsPerComment = 50

type ProductData struct {
	ProductMap map[string]Product
	PriceMap   map[string]SkuPrice
}

type DealData struct {
	psStoreLink  string
	submission   *geddit.Submission
	productData  ProductData
	productJSONs []string
}

// Deals maps reddit full ID to that deal's data
type Deals map[string]*DealData

// TODO: make sure we're not skipping too much.. does this match the final product count?
func getProductDataFromJSONStrings(pages []string) ProductData {
	productMap := make(map[string]Product)
	priceMap := make(map[string]SkuPrice)
	for _, page := range pages {
		var data AutoGenerated
		json.Unmarshal([]byte(page), &data)

		for k, v := range data.Props.ApolloState {
			apolloStateData, ok := v.(map[string]interface{})
			if !ok {
				fmt.Println("apollo state data is not a map[string]interface{}")
			}
			switch apolloStateData["__typename"] {

			case "Product":
				var product Product
				if err := mapstructure.Decode(apolloStateData, &product); err != nil {
					fmt.Println("could not decode appollo state data as a product")
				}
				productMap[product.ID] = product

			case "SkuPrice":
				var price SkuPrice
				if err := mapstructure.Decode(apolloStateData, &price); err != nil {
					fmt.Println("could not decode appollo state data as a price")
				}

				// not ideal hardcode, but k should be of form: $Product:UP9000-CUSA17357_00-STB0670000000000:en-us.price
				// TODO: consider how to make this less fragile
				productID := strings.Split(k, ":")[1]
				price.ProductID = productID

				priceMap[productID] = price

			}
		}
	}

	var productData ProductData
	productData.ProductMap = productMap
	productData.PriceMap = priceMap
	return productData
}

func useSampleData() []string {
	var pages []string

	sampleDataFiles, err := ioutil.ReadDir("sample-data")
	if err != nil {
		log.Fatal("Cannot read sample data directory: ", err)
	}

	for _, sampleDataFile := range sampleDataFiles {

		jsonFile, err := os.Open(fmt.Sprintf("sample-data/%s", sampleDataFile.Name()))
		if err != nil {
			fmt.Println("error reading json file: ", err)
		}
		defer jsonFile.Close()

		jsonBytes, err := ioutil.ReadAll(jsonFile)
		if err != nil {
			fmt.Println("error reading json bytes: ", err)
		}

		pages = append(pages, string(jsonBytes))
	}

	return pages

}

func createDealsFromSubmissions(submissions []*geddit.Submission) Deals {
	deals := make(Deals)

	for _, submission := range submissions {
		deals[submission.FullID] = &DealData{
			psStoreLink: submission.URL,
			submission:  submission,
		}
	}

	return deals
}

func (deals Deals) addProductDatatoDeals() {
	for _, dealData := range deals {
		pages := scrape(dealData.psStoreLink)
		productData := getProductDataFromJSONStrings(pages)
		fmt.Printf("There are %d products and %d prices\n", len(productData.ProductMap), len(productData.PriceMap))

		// TODO: add some real error handling here
		if len(productData.ProductMap) != len(productData.PriceMap) {
			fmt.Println("we don't have exactly one price for each product")
			continue
		}

		dealData.productData = productData

		_, numTables := productData.getTables()
		fmt.Printf("there are %d comments to write \n", numTables)
		// fmt.Println(tables)
	}
}

func main() {
	ctx := context.TODO()

	matchingSubmissions, err := getSubmissions(ctx)
	if err != nil {
		log.Printf("error getting latest submissions: %s", err)
	}

	deals := createDealsFromSubmissions(matchingSubmissions)
	deals.addProductDatatoDeals()
}

// Only works on links of the form https://store.playstation.com/en-us/category/3fc38af7-0e2c-4de6-a585-3e562e54b81e/1
// TODO: what if the link doesn't end in "/1" as it should?
// I think PS Store will handle it via redirect, but need to confirm
func scrape(startURL string) []string {
	// need to remove page number of original startURL
	urlParts := strings.Split(startURL, "/")
	baseURL := strings.Join(urlParts[0:len(urlParts)-1], "/")

	pageNumber := 1
	var jsonBodies []string
	c := colly.NewCollector(
		colly.AllowedDomains("store.playstation.com"),
	)

	c.OnRequest(func(r *colly.Request) {
		fmt.Println("Visiting: ", r.URL.String())
	})
	c.Limit(&colly.LimitRule{
		Delay:       3 * time.Second,
		RandomDelay: 5 * time.Second,
	})

	c.OnHTML("#__NEXT_DATA__", func(e *colly.HTMLElement) {
		fmt.Println("found next.js data! Will add it to the list...")
		jsonBodies = append(jsonBodies, e.Text)
	})

	c.OnHTML(`button[data-qa="ems-sdk-grid-paginator-next-page-btn"]`, func(e *colly.HTMLElement) {
		fmt.Println("found a next page button! Checking if it's disabled.")
		buttonIsDisabled := false
		for _, node := range e.DOM.Nodes {
			for _, attr := range node.Attr {
				if attr.Key == "disabled" {
					fmt.Println("Found disabled next button. Will stop here")
					buttonIsDisabled = true
					break
				}
			}
		}
		if !buttonIsDisabled {
			fmt.Printf("next page button is not disabled.  Visiting to next page: #%d\n", pageNumber+1)
			pageNumber++
			c.Visit(fmt.Sprintf("%s/%d", baseURL, pageNumber))
		}
	})

	c.Visit(fmt.Sprintf("%s/%d", baseURL, pageNumber))

	c.Wait()
	return jsonBodies
}

func (productData *ProductData) getProductRowChunks() [][]string {
	var productRows []string

	for _, product := range productData.ProductMap {
		productRow := productData.getProductRow(product)

		productRows = append(productRows, productRow)
	}

	// adapted from: https://freshman.tech/snippets/go/split-slice-into-chunks/
	// reddit max comment size is 10,000 characters, so we break up the comments here
	var chunks [][]string
	for i := 0; i < len(productRows); i += ProductsPerComment {
		end := i + ProductsPerComment

		if end > len(productRows) {
			end = len(productRows)
		}

		chunks = append(chunks, productRows[i:end])
	}
	return chunks
}

// TODO: sorted aphabetically or by price? currently there is no guarantee on ordering
// TODO: include PS plus vs not ps plus?
// TODO: what is the biggest comment we can make in a reddit comment?
func (productData *ProductData) getTables() ([]string, int) {
	// TODO: tie top row order to getProductRow return order to make less fragile
	topRow := "Title | Discounted price | % Off | Regular Price\n"
	alignmentRow := ":--|:--|:--|:--\n"

	productChunks := productData.getProductRowChunks()

	var tables []string
	for _, chunk := range productChunks {
		chunkString := strings.Join(chunk, "\n")
		tables = append(tables, topRow+alignmentRow+chunkString)
	}

	return tables, len(tables)
}

func (productData *ProductData) getProductRow(product Product) string {
	priceData := productData.PriceMap[product.ID]

	hyperlinkedName := fmt.Sprintf("[%s](%s)", product.Name, productURLPrefix+product.ID)

	// make sure this isn't fragile. possibly no guarantees
	discountedPrice := priceData.DiscountedPrice
	discountPercentage, ok := priceData.DiscountText.(string)
	if !ok {
		discountPercentage = "0%"
	}
	basePrice := priceData.BasePrice
	return fmt.Sprintf("%s | %s | %s | %s", hyperlinkedName, discountedPrice, discountPercentage, basePrice)
}
